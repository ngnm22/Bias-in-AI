# Bias-in-AI
This code analyses a human-centric 1 dataset and develop a fair machine learning ecosystem to detect, reduce and eventually mitigate different types of bias that exist in the final outcome of algorithms in various ways
Here we designed an adversarial bias mitigation algorithm to mitigate any potential bias in the decision making a job offer. We carefully design the adversarial part of our algorithm based on specific fairness definitions. This is split in two parts:

(1) the regular classifier implementation

(2) adversarial implementation.
